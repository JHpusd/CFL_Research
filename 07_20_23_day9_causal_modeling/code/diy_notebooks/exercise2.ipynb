{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cheninstitutecaltech/Caltech_DATASAI_Neuroscience_23/blob/main/07_20_23_day9_causal_modeling/code/solutions/exercise2.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal structure discovery: chain structure\n",
    "Authors: Iman Wahle and Frederick Eberhardt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will generate synthetic data from another hand-constructed \n",
    "model and use the PC algorithm to infer the underlying model. In particular,\n",
    "we will look at an example where all edges are not orientable from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_context('notebook')\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable # for making subplots with colorbars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'estimate_parameters.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colab setup\n",
    "!pip install -q corner gdown causal-learn\n",
    "import gdown\n",
    "gdown.download(\"https://drive.google.com/uc?export=view&id=1jxir2Cz-_IKtPuBH0ZonRR4ZN0uwCDnf\",\n",
    "               \"estimate_parameters.py\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to generate data with the following causal structure: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![exercise2_model.png](https://drive.google.com/uc?export=view&id=1uB-AUZ0yMlBK8nm79u_Wk7z7Zhi67cmM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, write a function `generate_data` that takes `n_samples` as an\n",
    "argument. The data for variables $A$, $B$, and $C$, should be generated as follows:\n",
    "\n",
    "- $A = \\varepsilon_A$, where $\\varepsilon_A \\sim \\mathcal{N}(0,1)$ \n",
    "- $B = aA + \\varepsilon_B$, where $\\varepsilon_B \\sim \\mathcal{N}(0,1)$ \n",
    "- $C = bB + \\varepsilon_C$, where $\\varepsilon_C \\sim \\mathcal{N}(0,1)$ \n",
    "\n",
    "$a$ and $b$ are constants you can set to whatever you like.\n",
    "\n",
    "Once the samples have been generated, z-score the data so that each variable\n",
    "has a mean of 0 and standard deviation of 1. \n",
    "\n",
    "The function should return:\n",
    "\n",
    "  - `data`: an `n_samples` x 3 numpy array where each column corresponds to\n",
    "    z-scored samples of $A$, $B$, and $C$.\n",
    "  - `var_names` : a list of variable names \n",
    "\n",
    "Finally, use your function to generate 5000 samples from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples=5000, noise_scale=1):\n",
    "\n",
    "    # add code here\n",
    "\n",
    "    pass\n",
    "\n",
    "data, var_names = generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin the analysis, it is important to make sure the data matches\n",
    "our expectations:\n",
    "\n",
    "1. Print out the shape of the data and the names of the variables included\n",
    "2. Construct a [corner plot](https://corner.readthedocs.io/en/latest/pages/quickstart/)\n",
    "   of the variable distributions\n",
    "3. Plot the correlation matrix over the three variables\n",
    "4. Plot the inverse of the correlation matrix (aka the \"precision matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data shape and variable labels\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a corner plot of the three variables\n",
    "from corner import corner\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlation matrix between the four variables (make sure to include \n",
    "# variable name labels!). Set the diagonal terms to 0 so that we can focus \n",
    "# on the relationships between variables.\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which entries do we expect to be zero/nonzero in the correlation matrix? \n",
    "Confirm that is the case in the plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the precision matrix between the three variables (make sure to include \n",
    "# variable name labels!). Set the diagonal terms to 0 so that we can focus \n",
    "# on the relationships between variables. \n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which entries do we expect to be zero/nonzero in the precision matrix? \n",
    "Confirm that is the case in the plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the PC algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have confirmed that our data looks as we expect, we are ready to \n",
    "use the PC algorithm to infer the causal graph that gave rise to this data.\n",
    "\n",
    "Call the `pc` function on the dataset generated above with `alpha=0.05` and \n",
    "`indep_test='fisherz'` to start. Feel free to come back later and try different \n",
    "values for these arguments to see how they change the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run PC algorithm\n",
    "\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "\n",
    "cg = pc(data, alpha=0.05, indep_test='fisherz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the inferred graph using cg.draw_pydot_graph\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "cg.draw_pydot_graph(labels=var_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the inferred PDAG in matrix form as well (this is stored at `cg.G.graph`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize PDAG matrix `cg.G.Graph`\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the edges in the recovered graph are not directed as they were in \n",
    "Exercise 1. Why is this the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the matrix representation of the PDAG into an adjacency matrix and\n",
    "visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PDAG matrix to adjacency matrix\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate edge weights and covariance matrix from inferred graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since PC algorithm has only returned a partially directed acyclic \n",
    "graph (PDAG), we need to convert this to a fully directed acyclic graph\n",
    "(DAG) in order to estimate edge weights across the graph (this can be any DAG\n",
    "in the equivalence class described by the PDAG). The `causal-learn` package\n",
    "has a utility function `pdag2dag` that takes in the graph object `cg.G` and \n",
    "returns a DAG.\n",
    "\n",
    "The source code for `pdag2dag` is\n",
    "[here](https://github.com/py-why/causal-learn/blob/main/causallearn/utils/PDAG2DAG.py)\n",
    "if you are interested in looking at the implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert partial DAG to full DAG\n",
    "\n",
    "from causallearn.utils.PDAG2DAG import pdag2dag\n",
    "\n",
    "G_DAG = pdag2dag(cg.G)\n",
    "dag_mat = G_DAG.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the resulting adjacency matrix `dag_mat` to confirm all edges are now oriented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, estimate the edge weights and residuals as you did in Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn edge weight estimates\n",
    "from estimate_parameters import estimate_parameters\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize both resulting matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the estimated weights and residuals compare to the original data \n",
    "generation model? What may explain any differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, estimate the correlation matrix from the inferred graph using the \n",
    "function you wrote in Exercise 1. Visualize the result and compare to the \n",
    "correlation matrix computed from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate correlation matrix\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the estimated correlation matrix (zero out the diagonal)\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantify how closely the estimated correlation matrix matches that found\n",
    "from the data. To do this, vectorize the lower-triangular elements in the true\n",
    "and estimated matrices and compute the Pearson correlation between the two vectors.\n",
    "\n",
    "`np.corrcoef` and `np.tril_indices` may be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
